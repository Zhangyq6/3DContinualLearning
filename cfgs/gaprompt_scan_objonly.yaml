optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.0005,
  weight_decay : 0.05
}}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 300,
    initial_epochs : 10
}}

dataset : {
  train : { _base_: cfgs/dataset_configs/ScanObjectNN_objectonly.yaml,
            others: {subset: 'train'}},
  val : { _base_: cfgs/dataset_configs/ScanObjectNN_objectonly.yaml,
            others: {subset: 'test'}},
  test : { _base_: cfgs/dataset_configs/ScanObjectNN_objectonly.yaml,
            others: {subset: 'test'}}}
model : {
  NAME: PointTransformer_pointtokenprompt,  #PointTransformer_pointtokenprompt
  trans_dim: 384,
  depth: 12,
  drop_path_rate: 0.1,
  if_half: False,
  cls_dim: 15,
  num_heads: 6,
  group_size: 32,
  num_group: 128,
  encoder_dims: 384,
  adapter_config: {
    adapter_dim: 16,
    adapter_drop_path_rate: 0.1,
  },
  point_number: 10,
  scale: 0.01,
  factor: 5,
  perturbation: 0.10,
  point_prompt: True,
  shift_net: True,
  prompt_depth: 6,
  scaler: False,
  num_tokens: 10,
  propagation_type: 'permutation_after_attention' # 'replacement_before_attention' 'permutation_before_attention' 'replacement_after_attention' 'permutation_after_attention'
}


npoints: 2048
total_bs : 32
step_per_update : 1
max_epoch : 300
grad_norm_clip : 10
task: 'classification'